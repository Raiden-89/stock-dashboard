# Stock Dashboard with Apache Airflow

This project implements a stock data ETL pipeline using **Apache Airflow** and **Yahoo Finance** data. It allows scheduled extraction and storage of historical stock prices for selected tickers into a PostgreSQL database.

## ğŸš€ Features

- Download daily stock data using `yfinance`
- Store it in a PostgreSQL database via SQLAlchemy
- Scheduled execution using Airflow DAGs
- Docker-based local development setup

## ğŸ—‚ Project Structure

```
stock-dashboard/
â”‚
â”œâ”€â”€ .venv/                     # Python virtual environment (excluded from version control)
â”‚
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                  # Airflow DAGs
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dag_prova.py
â”‚   â”‚   â””â”€â”€ etl_stock_data.py
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/               # Utility scripts for Airflow (e.g., user creation)
â”‚   â”‚   â””â”€â”€ create_user.sh
â”‚   â”‚
â”‚   â”œâ”€â”€ .env                   # Environment variables used by docker-compose and DAGs
â”‚   â”œâ”€â”€ docker-compose.yml     # Docker environment configuration
â”‚   â””â”€â”€ requirements.txt       # Python dependencies
â”‚
â””â”€â”€ README.md                  # Project documentation
```

## ğŸ§° Requirements

- Docker
- Docker Compose

## â–¶ï¸ How to Run

```bash
cd airflow/
docker-compose up --build
```

Then access the Airflow UI at [http://localhost:8080](http://localhost:8080)

## ğŸ“Š Environment Variables

Defined in `.env` (sample values):

```
STOCK_DB_HOST=stock_pg
STOCK_DB_PORT=5432
STOCK_DB_USER=stockuser
STOCK_DB_PASSWORD=stockpass
STOCK_DB_NAME=stockdb
```

## ğŸ“… Airflow DAGs

Main DAG: `etl_stock_data.py`  
Runs daily and processes data for these tickers:

```python
["AAPL", "MSFT", "SPY"]
```

## ğŸ“ License

MIT License
